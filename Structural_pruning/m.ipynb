{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_path='../Dataset/tire_data/tire_data/train'\n",
    "\n",
    "if '*.pt' in os.listdir(root_path):\n",
    "    print('True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HOJUN_~1\\AppData\\Local\\Temp/ipykernel_143692/84647232.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# model = torch.load('./20.pt')['model_state_dict']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./20.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# model = torch.load('./20.pt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# model.load_state_dict(torch.load('./20.pt'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchsummaryX\n",
    "from torchvision.models.resnet import resnet18\n",
    "\n",
    "\n",
    "# model = resnet18()\n",
    "# data = torch.zeros([1, 3, 640, 480], dtype=torch.float32)\n",
    "# torchsummaryX.summary(model, data)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================================\n",
      "                                          Kernel Shape       Output Shape  \\\n",
      "Layer                                                                       \n",
      "0_conv1                                  [3, 34, 7, 7]  [1, 34, 320, 240]   \n",
      "1_bn1                                             [34]  [1, 34, 320, 240]   \n",
      "2_relu                                               -  [1, 34, 320, 240]   \n",
      "3_maxpool                                            -  [1, 34, 160, 120]   \n",
      "4_layer1.0.Conv2d_conv1                 [34, 52, 3, 3]  [1, 52, 160, 120]   \n",
      "5_layer1.0.BatchNorm2d_bn1                        [52]  [1, 52, 160, 120]   \n",
      "6_layer1.0.ReLU_relu                                 -  [1, 52, 160, 120]   \n",
      "7_layer1.0.Conv2d_conv2                 [52, 34, 3, 3]  [1, 34, 160, 120]   \n",
      "8_layer1.0.BatchNorm2d_bn2                        [34]  [1, 34, 160, 120]   \n",
      "9_layer1.0.ReLU_relu                                 -  [1, 34, 160, 120]   \n",
      "10_layer1.1.Conv2d_conv1                [34, 52, 3, 3]  [1, 52, 160, 120]   \n",
      "11_layer1.1.BatchNorm2d_bn1                       [52]  [1, 52, 160, 120]   \n",
      "12_layer1.1.ReLU_relu                                -  [1, 52, 160, 120]   \n",
      "13_layer1.1.Conv2d_conv2                [52, 34, 3, 3]  [1, 34, 160, 120]   \n",
      "14_layer1.1.BatchNorm2d_bn2                       [34]  [1, 34, 160, 120]   \n",
      "15_layer1.1.ReLU_relu                                -  [1, 34, 160, 120]   \n",
      "16_layer1.2.Conv2d_conv1                [34, 52, 3, 3]  [1, 52, 160, 120]   \n",
      "17_layer1.2.BatchNorm2d_bn1                       [52]  [1, 52, 160, 120]   \n",
      "18_layer1.2.ReLU_relu                                -  [1, 52, 160, 120]   \n",
      "19_layer1.2.Conv2d_conv2                [52, 34, 3, 3]  [1, 34, 160, 120]   \n",
      "20_layer1.2.BatchNorm2d_bn2                       [34]  [1, 34, 160, 120]   \n",
      "21_layer1.2.ReLU_relu                                -  [1, 34, 160, 120]   \n",
      "22_layer2.0.Conv2d_conv1               [34, 103, 3, 3]   [1, 103, 80, 60]   \n",
      "23_layer2.0.BatchNorm2d_bn1                      [103]   [1, 103, 80, 60]   \n",
      "24_layer2.0.ReLU_relu                                -   [1, 103, 80, 60]   \n",
      "25_layer2.0.Conv2d_conv2               [103, 54, 3, 3]    [1, 54, 80, 60]   \n",
      "26_layer2.0.BatchNorm2d_bn2                       [54]    [1, 54, 80, 60]   \n",
      "27_layer2.0.downsample.Conv2d_0         [34, 54, 1, 1]    [1, 54, 80, 60]   \n",
      "28_layer2.0.downsample.BatchNorm2d_1              [54]    [1, 54, 80, 60]   \n",
      "29_layer2.0.ReLU_relu                                -    [1, 54, 80, 60]   \n",
      "30_layer2.1.Conv2d_conv1               [54, 103, 3, 3]   [1, 103, 80, 60]   \n",
      "31_layer2.1.BatchNorm2d_bn1                      [103]   [1, 103, 80, 60]   \n",
      "32_layer2.1.ReLU_relu                                -   [1, 103, 80, 60]   \n",
      "33_layer2.1.Conv2d_conv2               [103, 54, 3, 3]    [1, 54, 80, 60]   \n",
      "34_layer2.1.BatchNorm2d_bn2                       [54]    [1, 54, 80, 60]   \n",
      "35_layer2.1.ReLU_relu                                -    [1, 54, 80, 60]   \n",
      "36_layer2.2.Conv2d_conv1               [54, 103, 3, 3]   [1, 103, 80, 60]   \n",
      "37_layer2.2.BatchNorm2d_bn1                      [103]   [1, 103, 80, 60]   \n",
      "38_layer2.2.ReLU_relu                                -   [1, 103, 80, 60]   \n",
      "39_layer2.2.Conv2d_conv2               [103, 54, 3, 3]    [1, 54, 80, 60]   \n",
      "40_layer2.2.BatchNorm2d_bn2                       [54]    [1, 54, 80, 60]   \n",
      "41_layer2.2.ReLU_relu                                -    [1, 54, 80, 60]   \n",
      "42_layer2.3.Conv2d_conv1               [54, 103, 3, 3]   [1, 103, 80, 60]   \n",
      "43_layer2.3.BatchNorm2d_bn1                      [103]   [1, 103, 80, 60]   \n",
      "44_layer2.3.ReLU_relu                                -   [1, 103, 80, 60]   \n",
      "45_layer2.3.Conv2d_conv2               [103, 54, 3, 3]    [1, 54, 80, 60]   \n",
      "46_layer2.3.BatchNorm2d_bn2                       [54]    [1, 54, 80, 60]   \n",
      "47_layer2.3.ReLU_relu                                -    [1, 54, 80, 60]   \n",
      "48_layer3.0.Conv2d_conv1               [54, 205, 3, 3]   [1, 205, 40, 30]   \n",
      "49_layer3.0.BatchNorm2d_bn1                      [205]   [1, 205, 40, 30]   \n",
      "50_layer3.0.ReLU_relu                                -   [1, 205, 40, 30]   \n",
      "51_layer3.0.Conv2d_conv2               [205, 68, 3, 3]    [1, 68, 40, 30]   \n",
      "52_layer3.0.BatchNorm2d_bn2                       [68]    [1, 68, 40, 30]   \n",
      "53_layer3.0.downsample.Conv2d_0         [54, 68, 1, 1]    [1, 68, 40, 30]   \n",
      "54_layer3.0.downsample.BatchNorm2d_1              [68]    [1, 68, 40, 30]   \n",
      "55_layer3.0.ReLU_relu                                -    [1, 68, 40, 30]   \n",
      "56_layer3.1.Conv2d_conv1               [68, 205, 3, 3]   [1, 205, 40, 30]   \n",
      "57_layer3.1.BatchNorm2d_bn1                      [205]   [1, 205, 40, 30]   \n",
      "58_layer3.1.ReLU_relu                                -   [1, 205, 40, 30]   \n",
      "59_layer3.1.Conv2d_conv2               [205, 68, 3, 3]    [1, 68, 40, 30]   \n",
      "60_layer3.1.BatchNorm2d_bn2                       [68]    [1, 68, 40, 30]   \n",
      "61_layer3.1.ReLU_relu                                -    [1, 68, 40, 30]   \n",
      "62_layer3.2.Conv2d_conv1               [68, 205, 3, 3]   [1, 205, 40, 30]   \n",
      "63_layer3.2.BatchNorm2d_bn1                      [205]   [1, 205, 40, 30]   \n",
      "64_layer3.2.ReLU_relu                                -   [1, 205, 40, 30]   \n",
      "65_layer3.2.Conv2d_conv2               [205, 68, 3, 3]    [1, 68, 40, 30]   \n",
      "66_layer3.2.BatchNorm2d_bn2                       [68]    [1, 68, 40, 30]   \n",
      "67_layer3.2.ReLU_relu                                -    [1, 68, 40, 30]   \n",
      "68_layer3.3.Conv2d_conv1               [68, 205, 3, 3]   [1, 205, 40, 30]   \n",
      "69_layer3.3.BatchNorm2d_bn1                      [205]   [1, 205, 40, 30]   \n",
      "70_layer3.3.ReLU_relu                                -   [1, 205, 40, 30]   \n",
      "71_layer3.3.Conv2d_conv2               [205, 68, 3, 3]    [1, 68, 40, 30]   \n",
      "72_layer3.3.BatchNorm2d_bn2                       [68]    [1, 68, 40, 30]   \n",
      "73_layer3.3.ReLU_relu                                -    [1, 68, 40, 30]   \n",
      "74_layer3.4.Conv2d_conv1               [68, 205, 3, 3]   [1, 205, 40, 30]   \n",
      "75_layer3.4.BatchNorm2d_bn1                      [205]   [1, 205, 40, 30]   \n",
      "76_layer3.4.ReLU_relu                                -   [1, 205, 40, 30]   \n",
      "77_layer3.4.Conv2d_conv2               [205, 68, 3, 3]    [1, 68, 40, 30]   \n",
      "78_layer3.4.BatchNorm2d_bn2                       [68]    [1, 68, 40, 30]   \n",
      "79_layer3.4.ReLU_relu                                -    [1, 68, 40, 30]   \n",
      "80_layer3.5.Conv2d_conv1               [68, 205, 3, 3]   [1, 205, 40, 30]   \n",
      "81_layer3.5.BatchNorm2d_bn1                      [205]   [1, 205, 40, 30]   \n",
      "82_layer3.5.ReLU_relu                                -   [1, 205, 40, 30]   \n",
      "83_layer3.5.Conv2d_conv2               [205, 68, 3, 3]    [1, 68, 40, 30]   \n",
      "84_layer3.5.BatchNorm2d_bn2                       [68]    [1, 68, 40, 30]   \n",
      "85_layer3.5.ReLU_relu                                -    [1, 68, 40, 30]   \n",
      "86_layer4.0.Conv2d_conv1               [68, 410, 3, 3]   [1, 410, 20, 15]   \n",
      "87_layer4.0.BatchNorm2d_bn1                      [410]   [1, 410, 20, 15]   \n",
      "88_layer4.0.ReLU_relu                                -   [1, 410, 20, 15]   \n",
      "89_layer4.0.Conv2d_conv2              [410, 263, 3, 3]   [1, 263, 20, 15]   \n",
      "90_layer4.0.BatchNorm2d_bn2                      [263]   [1, 263, 20, 15]   \n",
      "91_layer4.0.downsample.Conv2d_0        [68, 263, 1, 1]   [1, 263, 20, 15]   \n",
      "92_layer4.0.downsample.BatchNorm2d_1             [263]   [1, 263, 20, 15]   \n",
      "93_layer4.0.ReLU_relu                                -   [1, 263, 20, 15]   \n",
      "94_layer4.1.Conv2d_conv1              [263, 410, 3, 3]   [1, 410, 20, 15]   \n",
      "95_layer4.1.BatchNorm2d_bn1                      [410]   [1, 410, 20, 15]   \n",
      "96_layer4.1.ReLU_relu                                -   [1, 410, 20, 15]   \n",
      "97_layer4.1.Conv2d_conv2              [410, 263, 3, 3]   [1, 263, 20, 15]   \n",
      "98_layer4.1.BatchNorm2d_bn2                      [263]   [1, 263, 20, 15]   \n",
      "99_layer4.1.ReLU_relu                                -   [1, 263, 20, 15]   \n",
      "100_layer4.2.Conv2d_conv1             [263, 410, 3, 3]   [1, 410, 20, 15]   \n",
      "101_layer4.2.BatchNorm2d_bn1                     [410]   [1, 410, 20, 15]   \n",
      "102_layer4.2.ReLU_relu                               -   [1, 410, 20, 15]   \n",
      "103_layer4.2.Conv2d_conv2             [410, 263, 3, 3]   [1, 263, 20, 15]   \n",
      "104_layer4.2.BatchNorm2d_bn2                     [263]   [1, 263, 20, 15]   \n",
      "105_layer4.2.ReLU_relu                               -   [1, 263, 20, 15]   \n",
      "106_avgpool                                          -     [1, 263, 1, 1]   \n",
      "107_fc                                     [263, 1000]          [1, 1000]   \n",
      "\n",
      "                                       Params  Mult-Adds  \n",
      "Layer                                                     \n",
      "0_conv1                                4.998k  383.8464M  \n",
      "1_bn1                                    68.0       34.0  \n",
      "2_relu                                      -          -  \n",
      "3_maxpool                                   -          -  \n",
      "4_layer1.0.Conv2d_conv1               15.912k  305.5104M  \n",
      "5_layer1.0.BatchNorm2d_bn1              104.0       52.0  \n",
      "6_layer1.0.ReLU_relu                        -          -  \n",
      "7_layer1.0.Conv2d_conv2               15.912k  305.5104M  \n",
      "8_layer1.0.BatchNorm2d_bn2               68.0       34.0  \n",
      "9_layer1.0.ReLU_relu                        -          -  \n",
      "10_layer1.1.Conv2d_conv1              15.912k  305.5104M  \n",
      "11_layer1.1.BatchNorm2d_bn1             104.0       52.0  \n",
      "12_layer1.1.ReLU_relu                       -          -  \n",
      "13_layer1.1.Conv2d_conv2              15.912k  305.5104M  \n",
      "14_layer1.1.BatchNorm2d_bn2              68.0       34.0  \n",
      "15_layer1.1.ReLU_relu                       -          -  \n",
      "16_layer1.2.Conv2d_conv1              15.912k  305.5104M  \n",
      "17_layer1.2.BatchNorm2d_bn1             104.0       52.0  \n",
      "18_layer1.2.ReLU_relu                       -          -  \n",
      "19_layer1.2.Conv2d_conv2              15.912k  305.5104M  \n",
      "20_layer1.2.BatchNorm2d_bn2              68.0       34.0  \n",
      "21_layer1.2.ReLU_relu                       -          -  \n",
      "22_layer2.0.Conv2d_conv1              31.518k  151.2864M  \n",
      "23_layer2.0.BatchNorm2d_bn1             206.0      103.0  \n",
      "24_layer2.0.ReLU_relu                       -          -  \n",
      "25_layer2.0.Conv2d_conv2              50.058k  240.2784M  \n",
      "26_layer2.0.BatchNorm2d_bn2             108.0       54.0  \n",
      "27_layer2.0.downsample.Conv2d_0        1.836k    8.8128M  \n",
      "28_layer2.0.downsample.BatchNorm2d_1    108.0       54.0  \n",
      "29_layer2.0.ReLU_relu                       -          -  \n",
      "30_layer2.1.Conv2d_conv1              50.058k  240.2784M  \n",
      "31_layer2.1.BatchNorm2d_bn1             206.0      103.0  \n",
      "32_layer2.1.ReLU_relu                       -          -  \n",
      "33_layer2.1.Conv2d_conv2              50.058k  240.2784M  \n",
      "34_layer2.1.BatchNorm2d_bn2             108.0       54.0  \n",
      "35_layer2.1.ReLU_relu                       -          -  \n",
      "36_layer2.2.Conv2d_conv1              50.058k  240.2784M  \n",
      "37_layer2.2.BatchNorm2d_bn1             206.0      103.0  \n",
      "38_layer2.2.ReLU_relu                       -          -  \n",
      "39_layer2.2.Conv2d_conv2              50.058k  240.2784M  \n",
      "40_layer2.2.BatchNorm2d_bn2             108.0       54.0  \n",
      "41_layer2.2.ReLU_relu                       -          -  \n",
      "42_layer2.3.Conv2d_conv1              50.058k  240.2784M  \n",
      "43_layer2.3.BatchNorm2d_bn1             206.0      103.0  \n",
      "44_layer2.3.ReLU_relu                       -          -  \n",
      "45_layer2.3.Conv2d_conv2              50.058k  240.2784M  \n",
      "46_layer2.3.BatchNorm2d_bn2             108.0       54.0  \n",
      "47_layer2.3.ReLU_relu                       -          -  \n",
      "48_layer3.0.Conv2d_conv1               99.63k   119.556M  \n",
      "49_layer3.0.BatchNorm2d_bn1             410.0      205.0  \n",
      "50_layer3.0.ReLU_relu                       -          -  \n",
      "51_layer3.0.Conv2d_conv2              125.46k   150.552M  \n",
      "52_layer3.0.BatchNorm2d_bn2             136.0       68.0  \n",
      "53_layer3.0.downsample.Conv2d_0        3.672k    4.4064M  \n",
      "54_layer3.0.downsample.BatchNorm2d_1    136.0       68.0  \n",
      "55_layer3.0.ReLU_relu                       -          -  \n",
      "56_layer3.1.Conv2d_conv1              125.46k   150.552M  \n",
      "57_layer3.1.BatchNorm2d_bn1             410.0      205.0  \n",
      "58_layer3.1.ReLU_relu                       -          -  \n",
      "59_layer3.1.Conv2d_conv2              125.46k   150.552M  \n",
      "60_layer3.1.BatchNorm2d_bn2             136.0       68.0  \n",
      "61_layer3.1.ReLU_relu                       -          -  \n",
      "62_layer3.2.Conv2d_conv1              125.46k   150.552M  \n",
      "63_layer3.2.BatchNorm2d_bn1             410.0      205.0  \n",
      "64_layer3.2.ReLU_relu                       -          -  \n",
      "65_layer3.2.Conv2d_conv2              125.46k   150.552M  \n",
      "66_layer3.2.BatchNorm2d_bn2             136.0       68.0  \n",
      "67_layer3.2.ReLU_relu                       -          -  \n",
      "68_layer3.3.Conv2d_conv1              125.46k   150.552M  \n",
      "69_layer3.3.BatchNorm2d_bn1             410.0      205.0  \n",
      "70_layer3.3.ReLU_relu                       -          -  \n",
      "71_layer3.3.Conv2d_conv2              125.46k   150.552M  \n",
      "72_layer3.3.BatchNorm2d_bn2             136.0       68.0  \n",
      "73_layer3.3.ReLU_relu                       -          -  \n",
      "74_layer3.4.Conv2d_conv1              125.46k   150.552M  \n",
      "75_layer3.4.BatchNorm2d_bn1             410.0      205.0  \n",
      "76_layer3.4.ReLU_relu                       -          -  \n",
      "77_layer3.4.Conv2d_conv2              125.46k   150.552M  \n",
      "78_layer3.4.BatchNorm2d_bn2             136.0       68.0  \n",
      "79_layer3.4.ReLU_relu                       -          -  \n",
      "80_layer3.5.Conv2d_conv1              125.46k   150.552M  \n",
      "81_layer3.5.BatchNorm2d_bn1             410.0      205.0  \n",
      "82_layer3.5.ReLU_relu                       -          -  \n",
      "83_layer3.5.Conv2d_conv2              125.46k   150.552M  \n",
      "84_layer3.5.BatchNorm2d_bn2             136.0       68.0  \n",
      "85_layer3.5.ReLU_relu                       -          -  \n",
      "86_layer4.0.Conv2d_conv1              250.92k    75.276M  \n",
      "87_layer4.0.BatchNorm2d_bn1             820.0      410.0  \n",
      "88_layer4.0.ReLU_relu                       -          -  \n",
      "89_layer4.0.Conv2d_conv2              970.47k   291.141M  \n",
      "90_layer4.0.BatchNorm2d_bn2             526.0      263.0  \n",
      "91_layer4.0.downsample.Conv2d_0       17.884k    5.3652M  \n",
      "92_layer4.0.downsample.BatchNorm2d_1    526.0      263.0  \n",
      "93_layer4.0.ReLU_relu                       -          -  \n",
      "94_layer4.1.Conv2d_conv1              970.47k   291.141M  \n",
      "95_layer4.1.BatchNorm2d_bn1             820.0      410.0  \n",
      "96_layer4.1.ReLU_relu                       -          -  \n",
      "97_layer4.1.Conv2d_conv2              970.47k   291.141M  \n",
      "98_layer4.1.BatchNorm2d_bn2             526.0      263.0  \n",
      "99_layer4.1.ReLU_relu                       -          -  \n",
      "100_layer4.2.Conv2d_conv1             970.47k   291.141M  \n",
      "101_layer4.2.BatchNorm2d_bn1            820.0      410.0  \n",
      "102_layer4.2.ReLU_relu                      -          -  \n",
      "103_layer4.2.Conv2d_conv2             970.47k   291.141M  \n",
      "104_layer4.2.BatchNorm2d_bn2            526.0      263.0  \n",
      "105_layer4.2.ReLU_relu                      -          -  \n",
      "106_avgpool                                 -          -  \n",
      "107_fc                                 264.0k     263.0k  \n",
      "------------------------------------------------------------------------------------------------\n",
      "                            Totals\n",
      "Total params              7.36267M\n",
      "Trainable params          7.36267M\n",
      "Non-trainable params           0.0\n",
      "Mult-Adds             7.375605362G\n",
      "================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hojun_window\\anaconda3\\envs\\yolov5\\lib\\site-packages\\torchsummaryX\\torchsummaryX.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_sum = df.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_conv1</th>\n",
       "      <td>[3, 34, 7, 7]</td>\n",
       "      <td>[1, 34, 320, 240]</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>383846400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_bn1</th>\n",
       "      <td>[34]</td>\n",
       "      <td>[1, 34, 320, 240]</td>\n",
       "      <td>68.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 34, 320, 240]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_maxpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 34, 160, 120]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_layer1.0.Conv2d_conv1</th>\n",
       "      <td>[34, 52, 3, 3]</td>\n",
       "      <td>[1, 52, 160, 120]</td>\n",
       "      <td>15912.0</td>\n",
       "      <td>305510400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103_layer4.2.Conv2d_conv2</th>\n",
       "      <td>[410, 263, 3, 3]</td>\n",
       "      <td>[1, 263, 20, 15]</td>\n",
       "      <td>970470.0</td>\n",
       "      <td>291141000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104_layer4.2.BatchNorm2d_bn2</th>\n",
       "      <td>[263]</td>\n",
       "      <td>[1, 263, 20, 15]</td>\n",
       "      <td>526.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105_layer4.2.ReLU_relu</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 263, 20, 15]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106_avgpool</th>\n",
       "      <td>-</td>\n",
       "      <td>[1, 263, 1, 1]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107_fc</th>\n",
       "      <td>[263, 1000]</td>\n",
       "      <td>[1, 1000]</td>\n",
       "      <td>264000.0</td>\n",
       "      <td>263000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Kernel Shape       Output Shape    Params  \\\n",
       "Layer                                                                         \n",
       "0_conv1                          [3, 34, 7, 7]  [1, 34, 320, 240]    4998.0   \n",
       "1_bn1                                     [34]  [1, 34, 320, 240]      68.0   \n",
       "2_relu                                       -  [1, 34, 320, 240]       NaN   \n",
       "3_maxpool                                    -  [1, 34, 160, 120]       NaN   \n",
       "4_layer1.0.Conv2d_conv1         [34, 52, 3, 3]  [1, 52, 160, 120]   15912.0   \n",
       "...                                        ...                ...       ...   \n",
       "103_layer4.2.Conv2d_conv2     [410, 263, 3, 3]   [1, 263, 20, 15]  970470.0   \n",
       "104_layer4.2.BatchNorm2d_bn2             [263]   [1, 263, 20, 15]     526.0   \n",
       "105_layer4.2.ReLU_relu                       -   [1, 263, 20, 15]       NaN   \n",
       "106_avgpool                                  -     [1, 263, 1, 1]       NaN   \n",
       "107_fc                             [263, 1000]          [1, 1000]  264000.0   \n",
       "\n",
       "                                Mult-Adds  \n",
       "Layer                                      \n",
       "0_conv1                       383846400.0  \n",
       "1_bn1                                34.0  \n",
       "2_relu                                NaN  \n",
       "3_maxpool                             NaN  \n",
       "4_layer1.0.Conv2d_conv1       305510400.0  \n",
       "...                                   ...  \n",
       "103_layer4.2.Conv2d_conv2     291141000.0  \n",
       "104_layer4.2.BatchNorm2d_bn2        263.0  \n",
       "105_layer4.2.ReLU_relu                NaN  \n",
       "106_avgpool                           NaN  \n",
       "107_fc                           263000.0  \n",
       "\n",
       "[108 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchsummaryX\n",
    "\n",
    "model = torch.load('./resnet18_80epoch_pruned.pt')\n",
    "data = torch.zeros([1, 3, 640, 480], dtype=torch.float32)\n",
    "torchsummaryX.summary(model, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('yolov5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bcbafe70f883e14d7611556a42c89c5818daa996ce73e89781e42f3f6c5db68d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
