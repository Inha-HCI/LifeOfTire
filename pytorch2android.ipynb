{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38743335293734793, 0.4753862913338889)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "math.sqrt(7) - math.sqrt(5.1), math.sqrt(5) - math.sqrt(3.1)\n",
    "# math.sqrt(1.9)\n",
    "# math.sqrt(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)        # 사전학습된 모델 가져옴\n",
    "model.eval()\n",
    "example = torch.rand(1, 3, 224, 224)                            # 모델 사이즈에 맞는 Tensor 생성\n",
    "traced_script_module = torch.jit.trace(model, example)          \n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)      \n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"app/src/main/assets/model.ptl\")  # 해당 코드 실행하면 app/src/main/assets dir에 model.ptl 생성됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>ptl 파일 생성할 때 gradle에 있는 `org.pytorch:pytorch_android_lite:1.10.0` 버젼과 Python의 Torch 버젼을 맞춰줘야함.<mark>  \n",
    "\n",
    "현재 나는 torch2android를 통해서만 ptl 파일로 converting 해야함!\n",
    "\n",
    "- 생성된 가중치파일이 Android app에서 asset으로 작동함  \n",
    "\n",
    "![](/images/2022-02-18-14-09-23.png)\n",
    "\n",
    "- build.gradle 의존성 셋팅\n",
    "\n",
    "  ```bash\n",
    "  repositories {\n",
    "      jcenter()\n",
    "  }\n",
    "\n",
    "  dependencies {\n",
    "      implementation 'org.pytorch:pytorch_android_lite:1.9.0'     // Pytorch Android API\n",
    "      implementation 'org.pytorch:pytorch_android_torchvision:1.9.0'      // android.media.Image -> android.graphics.Bitmap으로 바꿔주는 기능\n",
    "  }\n",
    "  ```\n",
    "\n",
    "- png, jpg 이미지 안드로이드 Bitmap 객체로 변환\n",
    "  \n",
    "  ```java\n",
    "  Bitmap bitmap = BitmapFactory.decodeStream(getAssets().open(\"image.jpg\"));\n",
    "  ```\n",
    "\n",
    "- **가중치 파일** 로드\n",
    "\n",
    "  ```java\n",
    "  Module module = Module.load(assetFilePath(this, \"model.ptl\"));\n",
    "  ```\n",
    "\n",
    "- Bitmap 객체 32bit float Tensor로 변환 및 전처리\n",
    "  - 주의사항으로 로드된 가중치파일이 학습할 때 아래 코드와 같은 `전처리`가 이루어진것으로 해야 성능 하락을 억제할 수 있음\n",
    "    ```java\n",
    "    Tensor inputTensor = TensorImageUtils.bitmapToFloat32Tensor(bitmap,\n",
    "        TensorImageUtils.TORCHVISION_NORM_MEAN_RGB, TensorImageUtils.TORCHVISION_NORM_STD_RGB);\n",
    "        // mean: ([0.485, 0.456, 0.406]) std: ([0.229, 0.224, 0.225])임. 얘네가 Imagenet 전체 데이터에 계산한 평균, 표준편차 값임\n",
    "        // 이미지 사이즈는 자동으로 정해주나..?\n",
    "    ```\n",
    "\n",
    "- Inference\n",
    "\n",
    "  ```java\n",
    "  Tensor outputTensor = module.forward(IValue.from(inputTensor)).toTensor();\n",
    "  float[] scores = outputTensor.getDataAsFloatArray();        // pretrained된 imagenet으로 진행했다면 (1, 1000)으로 output 나옴\n",
    "\n",
    "  float maxScore = -Float.MAX_VALUE;      \n",
    "  int maxScoreIdx = -1;\n",
    "  for (int i = 0; i < scores.length; i++) {       // Inference 값 중 가장 큰 값의 index 구함\n",
    "    if (scores[i] > maxScore) {\n",
    "      maxScore = scores[i];\n",
    "      maxScoreIdx = i;\n",
    "    }\n",
    "  }\n",
    "  String className = ImageNetClasses.IMAGENET_CLASSES[maxScoreIdx];\n",
    "  ```\n",
    "\n",
    "- 의문사항\n",
    "  - 왜 img, ptl을 assets 폴더에 두는거지?\n",
    "  - 평균이 0.5가 아니라 저렇게 나오는 이유가 있나..? 표준 정규화 거치면 무조건 평균 0, 표준편차 1로 되는거 아님?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\hojun_window/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from ast import Num\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.classifier[1] = nn.Linear(in_features=1280,out_features=7,bias=True)\n",
    "model.eval()\n",
    "example = torch.rand(1, 3, 252, 336)\n",
    "traced_script_module = torch.jit.trace(model, example)\n",
    "traced_script_module_optimized = optimize_for_mobile(traced_script_module)\n",
    "traced_script_module_optimized._save_for_lite_interpreter(\"app/src/main/assets/model_custom.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'name': 'minimal', 'test_dict': {'a': 1, 'b': 2}, 'test_list': ['1', '2', '3']}\n"
     ]
    }
   ],
   "source": [
    "class Test:\n",
    "  def __init__(self, name):\n",
    "    self.name = name\n",
    "    self.test_dict = {'a':1, 'b':2}\n",
    "    self.test_list = ['1', '2', '3']\n",
    "\n",
    "test_object = Test(\"minimal\")\n",
    "\n",
    "print(type(test_object.__dict__))\n",
    "print(test_object.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7ba9026efa9b1352d121bae584ac2b28cab970ad6fbe5084668ed2642b51044"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch2android')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
